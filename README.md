# ğŸ¥ AskVid - AI Video Question Answering

Your AI tutor for any YouTube video! Upload a YouTube link, and AskVid will transcribe the video and answer your questions about it.

## âœ¨ Features

- **ğŸ¬ YouTube Video Processing**: Paste any YouTube URL and extract audio
- **ğŸ¤ AI Transcription**: Convert video speech to text using OpenAI Whisper
- **ğŸ¤– AI Q&A**: Ask questions and get intelligent answers based on the video content
- **ğŸ“ Transcript Preview**: View the full transcript with collapsible interface
- **ğŸ“± Responsive Design**: Beautiful, modern UI that works on all devices
- **âš¡ Real-time Processing**: Fast, efficient video processing and Q&A

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- OpenAI API key
- FFmpeg (for audio processing)

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd askvid
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Install FFmpeg**
   - **macOS**: `brew install ffmpeg`
   - **Ubuntu/Debian**: `sudo apt install ffmpeg`
   - **Windows**: Download from [FFmpeg website](https://ffmpeg.org/download.html)

4. **Set up environment variables**
   ```bash
   cp env_example.txt .env
   ```
   Edit `.env` and add your OpenAI API key:
   ```
   OPENAI_API_KEY=your_actual_api_key_here
   ```

5. **Run the application**
   ```bash
   python app.py
   ```

6. **Open your browser**
   Navigate to `http://localhost:5000`

## ğŸ› ï¸ How It Works

1. **Video Input**: User pastes a YouTube URL
2. **Audio Extraction**: The app downloads and extracts audio from the video
3. **Transcription**: OpenAI Whisper converts speech to text
4. **Q&A Interface**: Users can ask questions about the video content
5. **AI Answers**: GPT-3.5-turbo provides intelligent answers based on the transcript

## ğŸ¯ Usage

1. **Paste a YouTube URL** in the input field
2. **Click "Process Video"** and wait for transcription
3. **Ask questions** about the video content
4. **View answers** from the AI tutor
5. **Toggle transcript** to see the full video text

## ğŸ—ï¸ Tech Stack

- **Backend**: Flask (Python)
- **Frontend**: HTML5, CSS3, JavaScript (Vanilla)
- **AI Services**: OpenAI (Whisper + GPT-3.5-turbo)
- **Video Processing**: yt-dlp, FFmpeg
- **Styling**: Custom CSS with gradients and animations

## ğŸ“ Project Structure

```
askvid/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ env_example.txt       # Environment variables template
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # Main HTML template
â””â”€â”€ static/
    â”œâ”€â”€ css/
    â”‚   â””â”€â”€ style.css    # Custom styles
    â””â”€â”€ js/
        â””â”€â”€ app.js       # Frontend JavaScript
```

## ğŸ”§ Configuration

### Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key (required)
- `FLASK_SECRET_KEY`: Secret key for Flask sessions (optional)

### API Keys Setup

1. **OpenAI API Key**:
   - Visit [OpenAI Platform](https://platform.openai.com/api-keys)
   - Create a new API key
   - Add it to your `.env` file

## ğŸš€ Deployment

### Local Development
```bash
python app.py
```

### Production Deployment

#### Option 1: Render
1. Connect your GitHub repository to Render
2. Set environment variables in Render dashboard
3. Deploy as a Python web service

#### Option 2: Heroku
1. Install Heroku CLI
2. Create `Procfile`:
   ```
   web: gunicorn app:app
   ```
3. Deploy: `heroku create && git push heroku main`

#### Option 3: Railway
1. Connect your GitHub repository to Railway
2. Set environment variables
3. Deploy automatically

## ğŸ¨ Customization

### Styling
- Edit `static/css/style.css` to customize colors, fonts, and layout
- The app uses CSS Grid and Flexbox for responsive design
- Gradient backgrounds and smooth animations included

### Features
- Add new AI models by modifying the `get_ai_answer()` function
- Implement video summarization in `app.py`
- Add user authentication and history tracking

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -am 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for providing the Whisper and GPT APIs
- yt-dlp for YouTube video processing
- Font Awesome for icons
- Inter font family for typography

## ğŸ“ Support

If you encounter any issues:

1. Check that all dependencies are installed
2. Verify your OpenAI API key is correct
3. Ensure FFmpeg is installed and accessible
4. Check the browser console for JavaScript errors

## ğŸ¯ Future Enhancements

- [ ] Video summarization
- [ ] Quiz generation from video content
- [ ] Multiple language support
- [ ] Voice-to-text for questions
- [ ] User accounts and history
- [ ] Batch processing for multiple videos
- [ ] Export transcripts and Q&A sessions

---

**Built with â¤ï¸ for learners everywhere**

*AskVid - Making video learning smarter, one question at a time.* 